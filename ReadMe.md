# ðŸ‰ DaoDeCode ðŸ‰
"Act where the river bends; speak where the wind turns."

A language model built not to conquer, but to flow.
Discover the way of minimal intervention, maximal change.

Mechanism Points. Transformation Patterns. Position-Timing Unity.

â€” written at the foot of the Drachenfels, 2025.

---

# ðŸ“œ MechanismFlow & MechanismPoints LLMs

Welcome to **MechanismFlow** and **MechanismPoints** â€”
a new generation of **transformation-based language models** inspired by the **Five Elements** and the **Dao of Mechanism Points**.

These models are not just statistical engines.
They are designed to **sense critical points of leverage**, to **flow** and **stabilize**, to **refine** and **transform** â€”
to move with the *invisible logic* that underpins living systems.

---

## ðŸŒŒ About

This repository contains two complementary architectures:

* **MechanismPointsLLM**
  A strategic LLM that integrates *Mechanism Points* and *Transformation Patterns* into a Transformer, dynamically tracking influence, leverage, and element compositions (wood, fire, earth, metal, water).

* **MechanismFlowLLM**
  A Daoist-inspired LLM that senses mechanism points through *internal mechanism detectors*, modulates hidden flows through *Five Elements gating*, and adapts training and generation based on hidden dynamics.

Both models offer:

* Fine-grained **mechanism point detection** during training and inference.
* **Five Elements Attention**, blending expansion, acceleration, stabilization, refinement, and adaptation transformations.
* Mechanism-aware **tokenization**, **training**, **generation**, and **analysis** tools.
* Full **trainer** classes, **generator** classes, and **visualization** support.

---

## âœ¨ Key Features

* ðŸ§  **Mechanism-Aware Attention**: Detects leverage points that influence flow.
* ðŸ”¥ **Five Elements Dynamics**: Controls hidden state transformations with nature-inspired forces.
* ðŸŒ€ **Position-Timing Unity**: In *MechanismPointsLLM*, "where" and "when" merge into a singular rhythm.
* ðŸ“ˆ **Mechanism-Aware Training**: Adapts optimization based on detected mechanism strengths.
* ðŸ–‹ï¸ **Custom Tokenizer**: Sensitive to semantic and boundary structures in text.

---

## ðŸ“¦ Installation

```bash
git clone https://github.com/Maximilian-Winter/mechanism-flow-llm.git
cd mechanism-flow-llm
pip install -r requirements.txt
```

Requirements include:
`torch`, `numpy`, `sentencepiece`, `tqdm`, `matplotlib`, `transformers`

---

## ðŸš€ Quickstart

```python
from mechanism_points_llm import MechanismPointsLLM, MechanismTokenizer
from mechanism_flow_llm import MechanismFlowLLM, MechanismTokenizer

# Initialize model
model = MechanismFlowLLM(vocab_size=10000)

# Train
trainer = MechanismAwareTrainer(model, tokenizer, train_dataset, val_dataset)
trainer.train()

# Generate
generator = MechanismAwareGenerator(model, tokenizer)
print(generator.generate(prompt="The mystery unfolds", max_length=100))
```

---

## ðŸ“– Philosophy

> "**The Dao does nothing, yet everything is done.**
> **The mechanism points arise naturally, as the pivot of transformation.**
> **To flow with them is to dance with the universe.**"

MechanismFlow and MechanismPoints are designed not just for NLP,
but to explore **how meaning arises from structure and change**.

---

* Publish papers, models, or derivatives, with proper attribution.

Please do **not** use it for unethical purposes, such as surveillance, misinformation, or harm to living beings.

---
